
import json
import os
from dotenv import load_dotenv
from openai import OpenAI
from mofa.agent_build.base.base_agent import MofaAgent, run_agent
from mofa.utils.ai.conn import generate_json_from_llm
from mofa.utils.files.read import read_yaml
from create_agent_main import agent_config_dir_path
from pydantic import BaseModel, Field
from datetime import datetime
from typing import Optional

class AgentInfo(BaseModel):
    """
    Represents information about an agent, including its name, creation time,
    the Python code generated by the LLM, and an optional description.
    """
    agent_name: str = Field(..., description="The name of the agent.")
    creation_time: str = Field(..., description="The creation time of the agent.")
    llm_generated_code: str = Field(..., description="The Python code generated by the LLM.")
    description: Optional[str] = Field(None, description="An optional description of the agent.")


@run_agent
def run(agent: MofaAgent):
    # Load environment variables
    load_dotenv(os.path.join(agent_config_dir_path, '.env.secret'))

    os.environ['OPENAI_API_KEY'] = os.getenv('LLM_API_KEY')

    client = OpenAI( )

    prompt = read_yaml(file_path=os.path.join(agent_config_dir_path, 'configs', 'agent.yml')).get('agent', {}).get('prompt', '')

    user_query = agent.receive_parameter('query')

    messages = [
        {"role": "system", "content": json.dumps(prompt)},
        {"role": "user", "content": f"user q: {user_query}  "}
    ]
    result = generate_json_from_llm(client=client,messages=messages,format_class=AgentInfo,prompt=user_query)
    print('result : ',result.json())
    agent_info:dict = json.dumps(result.json())
    agent_info['file_name'] = 'main.py'

    agent.send_output(agent_output_name='create_agent_main_result', agent_result=agent_info)

def main():
    agent = MofaAgent(agent_name='create_agent_main')
    run(agent=agent)

if __name__ == "__main__":
    main()
