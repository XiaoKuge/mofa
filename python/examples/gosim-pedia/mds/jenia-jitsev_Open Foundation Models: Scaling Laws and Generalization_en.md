
# GOSIM AI Paris 2025

## Host Introduction

**Host:** *[With upbeat energy]*  
*"Ladies and gentlemen, good morning!*  

We‚Äôre about to dive into a session that‚Äôs as expansive as the datasets our next speaker works with‚Äîso buckle up. Please join me in welcoming **Jenia Jitsev**, Scientific Lead at LAION and Senior Researcher at the J√ºlich Supercomputing Center. Jenia isn‚Äôt just an expert in AI and high-performance computing; he‚Äôs also a champion of open-source research, having co-founded LAION and earned the *Falling Walls* 'Science Breakthrough of the Year' award. And if you‚Äôve ever used a massive open dataset like LAION-5B, you‚Äôve already benefited from his work‚Äîso feel free to silently thank him now.  

Today, Jenia will unpack **'Open Foundation Models: Scaling Laws and Generalization'**‚Äîa session that promises to demystify why open models and datasets are *non-negotiable* for advancing AI research. Expect insights on reproducible scaling laws, the challenges of measuring true generalization, and why transparency in AI isn‚Äôt just idealistic but *essential*.  

This is your chance to learn from someone who‚Äôs literally helping to build the open foundations of AI‚Äôs future. So grab your questions‚Äîor just your awe‚Äîand let‚Äôs give a warm welcome to **Jenia Jitsev!**"  

*(Lead applause, transition smoothly.)*  

---

## Track Information

### AI Model  
**Shaping the Future with Open-Source AI**  
Unleashing world-class performance in LLMs, multi-modal AI, cutting-edge image and video generation models, and pioneering on-device small LLMs pushing the boundaries of AI efficiency and accessibility.

---

## Event and Session Details

### Conference Overview  
- **Name:** GOSIM AI Paris 2025  
- **Dates:** May 6-7, 2025  
- **Location:** Station F, Paris, France  
- **Theme:** Driving progress in global open-source AI collaboration  
- **Tracks:** AI Model, AI Infra, AI Apps, Embodied AI, AI for Science, Global Open-Source AI Collaboration  

### Session Details  
- **Title:** Open Foundation Models: Scaling Laws and Generalization  
- **Date:** May 7, 2025  
- **Time:** 11:10 - 11:50  
- **Content:** To study transferable learning and generalization, derivation of reproducible scaling laws is crucial. We highlight why open foundation models and datasets are essential for this research and highlight challenges in properly measuring generalization.  

---

## Speaker Biography: Jenia Jitsev

### üß† Personal Information  
- **Full Name**: Jenia Jitsev  
- **Current Position**: Scientific Lead at LAION; Senior Researcher and Lab Leader at J√ºlich Supercomputing Center (JSC)  
- **Education**: PhD in Computer Science (Computational Neuroscience, Machine Learning)  
- **Location**: J√ºlich, Germany  

### üßµ Career Path (Timeline)  
- **2014**: Early experimentation in reinforcement learning, as seen in the [pong-RL GitHub repository](https://github.com/JeniaJitsev/pong-RL).  
- **2018**: Headed the Cross-Sectional Team "Deep Learning" (CST-DL) at J√ºlich Supercomputing Center (JSC), focusing on mechanisms of scalable learning and multi-purpose AI.  
- **2021**: Co-founded LAION e.V., a non-profit research organization dedicated to open-source AI research and datasets.  
- **2023**: Awarded "Science Breakthrough of the Year 2023" by the Falling Walls Foundation for contributions to open-source AI and large-scale datasets.  

### üîç Role  
Jenia Jitsev is a leading figure in the intersection of high-performance computing (HPC) and artificial intelligence (AI). As the Scientific Lead at LAION and a Senior Researcher at JSC, he focuses on scalable learning, multi-purpose AI, and the democratization of AI research through open-source datasets like LAION-400M and LAION-5B.  

### üìö Publications  
- **2022**: "LAION-5B: A New Era of Open Large-Scale Multi-Modal Datasets" ‚Äì Introduced a dataset of 5.85 billion CLIP-filtered image-text pairs, 14x larger than LAION-400M.  
  [Read the full paper here](https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/)  
- **2023**: "Resolving Discrepancies in Compute-Optimal Scaling of Language Models" ‚Äì Contributed to research on scaling laws for AI models.  
  [Read the full paper here](https://github.com/formll/resolving-scaling-law-discrepancies)  

### üèÜ Awards and Recognitions  
- **2023**: Falling Walls Award ‚Äì "Science Breakthrough of the Year 2023" in the category "Science and Innovation Management" for contributions to open-source AI research.  
- **2022**: Rising Star Award ‚Äì Recognized for contributions to scalable deep learning and AI research.  

### üé§ Media Appearances  
- **2023**: ML Conference ‚Äì Spoke on "AI as a Superpower: LAION and the Role of Open Source in Artificial Intelligence."  
  [Watch the video here](https://mlconference.ai/blog/ai-as-a-superpower-laion-and-the-role-of-open-source-in-artificial-intelligence/)  
- **2022**: NeurIPS 2022 ‚Äì Presented the LAION-5B dataset and its implications for open-source AI research.  

### üß† Personal Insights  
Jenia‚Äôs journey is marked by a passion for open-source research and a commitment to democratizing AI. His early experiments with reinforcement learning laid the foundation for his later work in scalable deep learning and HPC.  

### üîó Social Media Presence  
- **Twitter**: [@JJitsev](https://twitter.com/jjitsev)  
- **LinkedIn**: [Jenia Jitsev](https://www.linkedin.com/in/jenia-jitsev-11654427)  
- **GitHub**: [JeniaJitsev](https://github.com/JeniaJitsev)  
- **Website**: [LAION](https://laion.ai/)  

### üåç Influence and Impact  
Jenia Jitsev has significantly influenced the fields of scalable deep learning and open-source AI. His work on large-scale datasets like LAION-400M and LAION-5B has empowered researchers worldwide to advance AI research without proprietary constraints.  

### üì∏ Images  
![Jenia Jitsev at JSC](https://www.fz-juelich.de/en/ias/jsc/news/events/2018/hbp-colloquium-2018/jenia-jitsev)  
*Image Source: [Forschungszentrum J√ºlich](https://www.fz-juelich.de/en/ias/jsc/news/events/2018/hbp-colloquium-2018/jenia-jitsev)*  

### üé• Videos  
- **2023**: "AI as a Superpower: LAION and the Role of Open Source in Artificial Intelligence" ‚Äì ML Conference.  
  [Watch the video here](https://mlconference.ai/blog/ai-as-a-superpower-laion-and-the-role-of-open-source-in-artificial-intelligence/)  

### üìù Blogs  
- **2022**: "LAION-5B: A New Era of Open Large-Scale Multi-Modal Datasets" ‚Äì Discusses the creation and impact of the LAION-5B dataset.  
  [Read the blog here](https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/)  

### üîó Source Citations  
1. [Falling Walls Award Announcement](https://www.fz-juelich.de/en/ias/jsc/news/news-items/news-flashes/2023/laion-falling-walls-award)  
2. [LAION Team Profile](https://laion.ai/team/)  
3. [LinkedIn Profile](https://www.linkedin.com/in/jenia-jitsev-11654427)  
4. [ML Conference Blog](https://mlconference.ai/blog/ai-as-a-superpower-laion-and-the-role-of-open-source-in-artificial-intelligence/)  
5. [J√ºlich Supercomputing Centre](https://www.fz-juelich.de/en/ias/jsc/about-us/profile)  

By weaving together expertise in scalable deep learning, open-source advocacy, and collaborative innovation, Jenia Jitsev continues to inspire new generations in the fields of supercomputing and artificial intelligence.  

---

![Mofa](mofa.png)  
*Content Source: [MOFA](https://github.com/moxin-org/mofa)*  
