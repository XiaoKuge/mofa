
# GOSIM AI Paris 2025: Towards a Cerebrum-Cerebellum Collaboration Framework for Large Embodied Models

## üé§ Host Introduction

*"Ladies and gentlemen, a very warm welcome to this session!*  

We‚Äôre thrilled to have with us today **Dr. Cheng Chi**, Research Scientist at the Beijing Academy of Artificial Intelligence‚Äîor as I like to call him, the architect teaching AI how to *think* and *move* like a pro. With a Ph.D. in computer vision and a career spanning object detection, autonomous systems, and now embodied AI, Dr. Chi has been at the forefront of making machines not just smart, but also *adaptable*‚Äîwhether it‚Äôs spotting faces in a crowd or helping robots navigate the real world.  

Today, he‚Äôll take us on a fascinating journey with his talk: *‚ÄòTowards a Cerebrum-Cerebellum Collaboration Framework for Large Embodied Models.‚Äô* Ever wished your robot could plan like a genius *and* react like a gymnast? Dr. Chi‚Äôs work bridges high-level reasoning with lightning-fast sensorimotor control‚Äîessentially giving AI the best of both brains. We‚Äôre in for a session packed with cutting-edge insights, from model architectures to real-world applications in robotics.  

So, get those questions ready‚Äîbecause when it comes to embodied AI, curiosity is the best collaborator. Let‚Äôs give a warm welcome to **Dr. Cheng Chi!**"  

(*Applause, transition to speaker*)  

---

## üè∑Ô∏è Track Information: **Embodied AI**  
*"Propelling Open-Source Robotics Forward"*  
This track explores innovations in community-driven robot design, openly available datasets, advanced visual language models, and policy frameworks that define the future of autonomous systems.  

---

## üìÖ Event and Session Details  

### **Conference Overview**  
- **Name**: GOSIM AI Paris 2025  
- **Dates**: May 6-7, 2025  
- **Location**: Station F, Paris, France  
- **Theme**: *"Global Open-Source AI Collaboration"*  
- **Highlights**: Six tracks covering AI models, infrastructure, applications, embodied AI, AI for science, and open-source collaboration.  

### **Session Details**  
- **Title**: *Towards a Cerebrum-Cerebellum Collaboration Framework for Large Embodied Models*  
- **Date**: May 7, 2025  
- **Time**: 16:20 - 17:00 (CEST)  
- **Content**:  
  > Recent advances in large-scale multimodal models have significantly enhanced embodied AI systems, enabling more natural and adaptive interactions with the physical world. However, current models and frameworks often struggle with spatial-temporal perception, real-time and precise collaboration. Inspired by the biological synergy between the cerebrum and cerebellum, we propose a novel collaboration framework that integrates high-level cognitive reasoning with fast, low-latency sensorimotor adaptations. This talk explores how this framework can improve planning, error correction, and robustness in embodied AI. We will discuss model architectures, training strategies, and applications in robotic manipulation and human-robot interaction, paving the way for more agile and intelligent embodied systems.  

![Embodied AI](https://via.placeholder.com/800x400?text=Embodied+AI+Session)  
*Image: Conceptual illustration of cerebrum-cerebellum collaboration in AI systems.*  

---

## üë®‚Äçüî¨ Speaker Biography: **Cheng Chi**  

### üîç Personal Information  
- **Full Name**: Cheng Chi  
- **Current Position**: Research Scientist at Beijing Academy of Artificial Intelligence (BAAI)  
- **Education**:  
  - B.Eng. in Electrical and Information Engineering, Hunan University (2011‚Äì2015)  
  - Ph.D. in Pattern Recognition and Computer Vision, Chinese Academy of Sciences (2015‚Äì2020)  
  - Postdoctoral Researcher, Institute of Automation, Chinese Academy of Sciences (2020‚Äì2022)  
- **Location**: Beijing, China  

### üõ£Ô∏è Career Path  
- **2011‚Äì2015**: Undergraduate at Hunan University (Electrical Engineering/Computer Science).  
- **2015‚Äì2020**: Ph.D. at Chinese Academy of Sciences (Object/Face/Pedestrian Detection).  
- **2020‚Äì2022**: Postdoc at Chinese Academy of Sciences (Lidar/BEV Perception).  
- **2022‚Äì2024**: Principal Researcher at IDRIVERPLUS (3D Detection for Autonomous Vehicles).  
- **2024‚ÄìPresent**: Research Scientist at BAAI (Embodied AI, Vision-Language Models).  

### üéØ Role  
Cheng Chi pioneers embodied AI at BAAI, developing multimodal models to enhance AI perception, reasoning, and control.  

### üìö Key Publications  
- **2020**: *Selective Refinement Network for High Performance Face Detection*  
  [Paper Link](https://scholar.google.com/citations?user=wWGpskcAAAAJ&hl=zh-CN)  
- **2022**: *Lidar Perception in Autonomous Systems*  
  [Paper Link](https://scholar.google.com/citations?user=wWGpskcAAAAJ&hl=zh-CN)  

### üèÜ Awards  
- **2021**: China Postdoctoral Science Foundation Award.  
- **2020**: Tang Lixin Scholarship for Ph.D. Excellence.  

### üåç Media & Outreach  
- **2025**: Speaker at GOSIM AI Paris (*Large-Scale Multimodal Models*).  
  [Watch Here](https://paris2025.gosim.org/speakers/cheng-chi/)  

### üì∏ Profile  
![Cheng Chi](https://chicheng123.github.io/images/profile.jpg)  
*Image Source: [Cheng Chi's Homepage](https://chicheng123.github.io/)*  

### üîó Connect  
- **Twitter**: [@BAAIBeijing](https://x.com/baaibeijing?lang=en)  
- **GitHub**: [ChiCheng123](https://github.com/ChiCheng123)  
- **LinkedIn**: [Cheng Chi](https://www.linkedin.com/in/cheng-chi-5a964771/)  

---

![MOFA](mofa.png)  
*Content Source: [MOFA](https://github.com/moxin-org/mofa)*  
