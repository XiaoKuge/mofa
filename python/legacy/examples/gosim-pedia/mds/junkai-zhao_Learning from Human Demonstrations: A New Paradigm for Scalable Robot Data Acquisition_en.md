
# GOSIM AI Paris 2025

## Host Introduction

**Host:**  
*"Ladies and gentlemen, let’s give a warm welcome to our next speaker—someone who’s teaching robots to learn from us humans, because apparently, even machines need role models!*  

*Please welcome **Junkai Zhao**, Robotics Algorithm Engineer at the Beijing Academy of Artificial Intelligence, where he’s pioneering the future of general-purpose robotic manipulation. With a PhD candidacy at Nanyang Technological University and a trail of impressive work—from FPGA-based edge detection to calibrating imbalanced datasets—Junkai has been recognized as an Outstanding Open-Source Contributor and recently delivered a keynote at GOSIM AI Paris 2025. Clearly, when it comes to robots, he speaks their language—literally.*  

*Today, he’ll tackle one of robotics’ biggest challenges: scalable data acquisition. Forget clunky VR headsets or complex setups—Junkai’s approach lets robots learn just by watching us. Think of it as mentorship, but for machines. You’ll walk away understanding how this hardware-agnostic method could revolutionize robotic learning.*  

*So, get ready for a session packed with insights, and don’t hesitate to ask questions—after all, even the best algorithms need feedback! Let’s give it up for **Junkai Zhao**!"*  

*(Applause, transition to speaker.)*  

---

## Track Information

### **Embodied AI**  
**Propelling Open-Source Robotics Forward**  
Innovating community-driven robot design, expanding openly available datasets, developing advanced visual language models, and shaping policy frameworks that define the future of autonomous systems.

---

## Event and Session Details

### **Conference Overview**  
- **Name:** GOSIM AI Paris 2025  
- **Dates:** May 6-7, 2025  
- **Location:** Station F, Paris, France  
- **Theme:** Driving progress in global open-source AI collaboration  
- **Tracks:** AI Model, AI Infra, AI Apps, Embodied AI, AI for Science, Global Open-Source AI Collaboration  

### **Session Details**  
- **Title:** *Learning from Human Demonstrations: A New Paradigm for Scalable Robot Data Acquisition*  
- **Date:** May 7, 2025  
- **Time:** 14:40 - 15:20  
- **Content:**  
  Acquiring diverse and large-scale real-world robot data remains a critical bottleneck in training generalizable robotic action models. Efficient and scalable data collection has thus emerged as a key research focus in robotics.  

  A widely used method is teleoperation, where humans either wear VR devices or operate a secondary robot to guide actions. While effective, these approaches are limited by hardware-specific constraints and require complex setups, hindering scalability.  

  An emerging alternative is to learn directly from human demonstrations without relying on teleoperation hardware. This paradigm allows robots to acquire ta***REMOVED***relevant motion data by observing or interpreting natural human movements, offering a more flexible and hardware-agnostic solution.  

  In this talk, I will introduce a novel framework for robot data acquisition from human demonstrations. I will detail how it bypasses traditional teleoperation limitations and enables scalable learning across varied tasks and environments. By bridging the gap between human intent and robot execution, this method opens a promising direction for general-purpose robotic learning in the real world.  

![Session Photo](https://paris2025.gosim.org/speakers/junkai-zhao/)  
*Image credit: GOSIM AI Paris 2025*

---

## Speaker Biography

### **Junkai Zhao**  
**Current Position:** Robotics Algorithm Engineer, Beijing Academy of Artificial Intelligence (BAAI)  

### **Professional Background**  
- **Research Focus:** General-purpose robotic manipulation models, learning-based action modeling  
- **Education:** PhD candidate, Nanyang Technological University (Singapore)  

### **Key Career Milestones**  
- **2021-Present:** Leads algorithm development for robotic manipulation at BAAI  
- **2020-2021:** Research Assistant at Sichuan University (Machine Learning & Data Mining)  
- **Previous Engagements:** Motion planning and control systems at Agibot and Shanghai Qizhi Institute  

### **Technical Contributions**  
- Developed FPGA-based real-time edge detection systems  
- Pioneered calibration techniques for imbalanced datasets in machine learning  
- Contributed to open-source robotics frameworks in the Ascend Ecosystem  

### **Selected Publications**  
1. **Real-time Edge Detection System** (2021)  
   [IEEE Publication](https://ieeexplore.ieee.org/document/9137689/)  
2. **Imbalanced Data Calibration** (2020)  
   [Google Scholar Profile](https://scholar.google.com/citations?user=adez4W8AAAAJ)  

### **Industry Recognition**  
- **2021:** Outstanding Open-Source Contributor (Ascend Ecosystem)  

### **Recent Speaking Engagement**  
- **GOSIM AI Paris 2025:** Keynote on human demonstration learning in robotics  
  [Event Recording](https://medium.com/@gosimfoundation/unlock-the-future-of-intelligent-machines)  

### **Digital Presence**  
- [LinkedIn Profile](https://sg.linkedin.com/in/junkai-zhao-959aa2201)  
- [Google Scholar](https://scholar.google.com/citations?user=adez4W8AAAAJ)  

### **Visual Media**  
![Speaker Portrait](https://paris2025.gosim.org/speakers/junkai-zhao/)  
*Image credit: GOSIM AI Paris 2025*  

### **Source References**  
1. IEEE Xplore Author Profile  
2. Official GOSIM Conference Materials  
3. Academic Citation Databases  

---

![Mofa](mofa.png)  
*Content Source: [MOFA](https://github.com/moxin-org/mofa)*  
